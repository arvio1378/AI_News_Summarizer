{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7ab1cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from newspaper import Article\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1a2ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>content language</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://edition.cnn.com/world/live-news/israel...</td>\n",
       "      <td>Live updates: Israel carries out attack in Qat...</td>\n",
       "      <td>A man looking at smoke billowing after explosi...</td>\n",
       "      <td>English</td>\n",
       "      <td>Israel has launched a military strike on Qatar...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.cnnindonesia.com/internasional/202...</td>\n",
       "      <td>Kerusuhan di Nepal, KBRI Dhaka Pastikan WNI Aman</td>\n",
       "      <td>--\\n\\nAksi protes yang dilakukan oleh Generasi...</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>KBRI Dhaka mengeluarkan imbauan kepada seluruh...</td>\n",
       "      <td>Indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.cnnindonesia.com/internasional/202...</td>\n",
       "      <td>Presiden Mundur Susul PM, Nepal Chaos Terancam...</td>\n",
       "      <td>--\\n\\nPresiden Nepal Ram Chandra Poudel mengun...</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Presiden Nepal Ram Chandra Poudel mengundurkan...</td>\n",
       "      <td>Indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://edition.cnn.com/2025/09/09/europe/russ...</td>\n",
       "      <td>Russian aerial bomb kills at least 24 civilian...</td>\n",
       "      <td>Russia War in Ukraine See all topics Follow\\n\\...</td>\n",
       "      <td>English</td>\n",
       "      <td>This is a full transcript of the killings of a...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://edition.cnn.com/2025/09/09/europe/fran...</td>\n",
       "      <td>France‚Äôs government has collapsed again. How d...</td>\n",
       "      <td>Paris ‚Äî\\n\\nFrance‚Äôs prime minister has quit af...</td>\n",
       "      <td>English</td>\n",
       "      <td>Why do French governments keep collapsing? The...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://edition.cnn.com/world/live-news/israel...   \n",
       "1  https://www.cnnindonesia.com/internasional/202...   \n",
       "2  https://www.cnnindonesia.com/internasional/202...   \n",
       "3  https://edition.cnn.com/2025/09/09/europe/russ...   \n",
       "4  https://edition.cnn.com/2025/09/09/europe/fran...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Live updates: Israel carries out attack in Qat...   \n",
       "1   Kerusuhan di Nepal, KBRI Dhaka Pastikan WNI Aman   \n",
       "2  Presiden Mundur Susul PM, Nepal Chaos Terancam...   \n",
       "3  Russian aerial bomb kills at least 24 civilian...   \n",
       "4  France‚Äôs government has collapsed again. How d...   \n",
       "\n",
       "                                             content content language  \\\n",
       "0  A man looking at smoke billowing after explosi...          English   \n",
       "1  --\\n\\nAksi protes yang dilakukan oleh Generasi...        Indonesia   \n",
       "2  --\\n\\nPresiden Nepal Ram Chandra Poudel mengun...        Indonesia   \n",
       "3  Russia War in Ukraine See all topics Follow\\n\\...          English   \n",
       "4  Paris ‚Äî\\n\\nFrance‚Äôs prime minister has quit af...          English   \n",
       "\n",
       "                                             summary summary language  \n",
       "0  Israel has launched a military strike on Qatar...          English  \n",
       "1  KBRI Dhaka mengeluarkan imbauan kepada seluruh...        Indonesia  \n",
       "2  Presiden Nepal Ram Chandra Poudel mengundurkan...        Indonesia  \n",
       "3  This is a full transcript of the killings of a...          English  \n",
       "4  Why do French governments keep collapsing? The...          English  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/history.csv\", delimiter=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e3f684",
   "metadata": {},
   "source": [
    "### Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b301eb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ambil kolom content\n",
    "texts = df[\"content\"].dropna().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "64c7d60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Arvio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "stopwords_id = stopwords.words(\"indonesian\")\n",
    "stopwords_en = stopwords.words(\"english\")\n",
    "stopwords_all = set(stopwords_id + stopwords_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6199b514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z\\u00C0-\\u024F\\u1E00-\\u1EFF]+\", \" \", text)  # hapus simbol\n",
    "    tokens = text.split()\n",
    "    tokens = [t for t in tokens if t not in stopwords_all and len(t) > 2]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "texts_clean = [clean_text(t) for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "39e519d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 kata paling sering muncul:\n",
      "apple 41\n",
      "iphone 41\n",
      "tariffs 30\n",
      "new 26\n",
      "court 26\n",
      "trump 21\n",
      "menteri 19\n",
      "qatar 18\n",
      "said 18\n",
      "president 18\n"
     ]
    }
   ],
   "source": [
    "words = \" \".join(texts_clean).split()\n",
    "word_freq = Counter(words).most_common(10)\n",
    "\n",
    "print(\"20 kata paling sering muncul:\")\n",
    "for w, f in word_freq:\n",
    "    print(w, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1176061",
   "metadata": {},
   "source": [
    "### Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f84ba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "# save_path = \"../models/embedding/all-mpnet-base-v2\"\n",
    "# embedding_model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6e9807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat model embedding multilingual\n",
    "embedding_model = SentenceTransformer(\"../models/embedding/all-mpnet-base-v2\")\n",
    "\n",
    "umap_model = UMAP(n_neighbors=15, n_components=10, min_dist=0.0, metric=\"cosine\")\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=2, metric=\"euclidean\", cluster_selection_method=\"eom\")\n",
    "\n",
    "# Fit BERTopic\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    nr_topics=\"auto\"\n",
    ")\n",
    "\n",
    "topics, probs = topic_model.fit_transform(texts_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dd47ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìå Topik 0 (Jumlah dokumen: 6)\n",
      "üîë Kata kunci: apple, iphone, tariffs, new, court, trump\n",
      "üìù Contoh kalimat:\n",
      "   - paris france prime minister quit losing confidence vote toppled government plunging country new political crisis fran√ßoi...\n",
      "   - tech giants corporate news tech news see topics follow new york apple announced first major redesign iphone years tuesda...\n",
      "============================================================\n",
      "üìå Topik 1 (Jumlah dokumen: 6)\n",
      "üîë Kata kunci: menteri, nepal, prabowo, sri, mulyani, keuangan\n",
      "üìù Contoh kalimat:\n",
      "   - menteri keuangan menkeu purbaya yudhi sadewa memuji kinerja ekonomi pemerintahan presiden prabowo subianto mengucap syuk...\n",
      "   - media asing reuters mengungkap detik detik presiden prabowo subianto memutuskan mencopot sri mulyani posisinya menteri k...\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def topics_user(topic_model, n_words=6, n_examples=1):\n",
    "    topic_info = topic_model.get_topic_info()\n",
    "    for _, row in topic_info.iterrows():\n",
    "        topic_id = row[\"Topic\"]\n",
    "        count = row[\"Count\"]\n",
    "\n",
    "        # Lewati outlier (-1) biar fokus ke topik jelas\n",
    "        if topic_id == -1:\n",
    "            continue\n",
    "\n",
    "        # Kata kunci topik\n",
    "        keywords = [w for w, _ in topic_model.get_topic(topic_id)[:n_words]]\n",
    "\n",
    "        # Contoh kalimat nyata\n",
    "        examples = topic_model.get_representative_docs(topic_id)[:n_examples]\n",
    "\n",
    "        # Cetak hasil\n",
    "        print(\"=\"*60)\n",
    "        print(f\"üìå Topik {topic_id} (Jumlah dokumen: {count})\")\n",
    "        print(f\"üîë Kata kunci: {', '.join(keywords)}\")\n",
    "        print(\"üìù Contoh kalimat:\")\n",
    "        for ex in examples:\n",
    "            print(f\"   - {ex[:120]}...\")  # dipotong biar tidak terlalu panjang\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# 5. Cetak hasil untuk user\n",
    "topics_user(topic_model, n_words=6, n_examples=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4d1efe",
   "metadata": {},
   "source": [
    "### Load model summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3996415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "c:\\Users\\Arvio\\anaconda3\\envs\\summarizer\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Arvio\\anaconda3\\envs\\summarizer\\Lib\\site-packages\\transformers\\modeling_utils.py:4034: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 84, 'num_beams': 4, 'length_penalty': 0.6, 'no_repeat_ngram_size': 2}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../models/summarizer/csebuetnlp/mT5_multilingual_XLSum\n"
     ]
    }
   ],
   "source": [
    "model_name = \"csebuetnlp/mT5_multilingual_XLSum\"\n",
    "\n",
    "save_path_summarizer = \"../models/summarizer/csebuetnlp/mT5_multilingual_XLSum\"\n",
    "\n",
    "# download ke cache\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# save model\n",
    "tokenizer.save_pretrained(save_path_summarizer)\n",
    "model.save_pretrained(save_path_summarizer)\n",
    "\n",
    "print(\"Model saved to\", save_path_summarizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d66ff46",
   "metadata": {},
   "source": [
    "### Load model translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b6f98a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arvio\\anaconda3\\envs\\summarizer\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "c:\\Users\\Arvio\\anaconda3\\envs\\summarizer\\Lib\\site-packages\\transformers\\modeling_utils.py:4034: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[54795]]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Arvio\\anaconda3\\envs\\summarizer\\Lib\\site-packages\\transformers\\modeling_utils.py:4034: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[54795]]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../models/translator/Helsinki-NLP/opus-mt-id-en\\\\tokenizer_config.json',\n",
       " '../models/translator/Helsinki-NLP/opus-mt-id-en\\\\special_tokens_map.json',\n",
       " '../models/translator/Helsinki-NLP/opus-mt-id-en\\\\vocab.json',\n",
       " '../models/translator/Helsinki-NLP/opus-mt-id-en\\\\source.spm',\n",
       " '../models/translator/Helsinki-NLP/opus-mt-id-en\\\\target.spm',\n",
       " '../models/translator/Helsinki-NLP/opus-mt-id-en\\\\added_tokens.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inggris to Indonesia\n",
    "engtoid = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-id\")\n",
    "# Indonesia to Inggris\n",
    "idtoeng = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-id-en\")\n",
    "\n",
    "# tempat simpan path\n",
    "save_path_translator_en_id = \"../models/translator/Helsinki-NLP/opus-mt-en-id\"\n",
    "save_path_translator_id_en = \"../models/translator/Helsinki-NLP/opus-mt-id-en\"\n",
    "\n",
    "# save model en-id\n",
    "engtoid.model.save_pretrained(save_path_translator_en_id)\n",
    "engtoid.tokenizer.save_pretrained(save_path_translator_en_id)\n",
    "\n",
    "# save model id-en\n",
    "idtoeng.model.save_pretrained(save_path_translator_id_en)\n",
    "idtoeng.tokenizer.save_pretrained(save_path_translator_id_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "99653990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_article(url):\n",
    "    article = Article(url)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    return article.title, article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "521b57e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Kejagung Tetapkan Nadiem Makarim Tersangka Kasus Pengadaan Laptop\n",
      "Content: --\n",
      "\n",
      "Eks Mendikbudristek Nadiem Makarim ditetapkan sebagai tersangka oleh Kejaksaan Agung (Kejagung) dalam kasus dugaan korupsi Program Digitalisasi Pendidikan di Kemendikbudristek periode 2019-2022.\n",
      "\n",
      "\"Dari hasil pendalaman dan alat bukti yang ada, pada sore ini telah menetapkan tersangka baru dengan inisial NAM (Nadiem Anwar Makarim),\" ujar Kapuspen Kejagung Anang Supriatna dalam konferensi pers di kompleks Kejagung, Jakarta Selatan, Kamis (4/9).\n",
      "\n",
      "Sebelumnya, pada Kamis pagi ini, Nadiem mendatangi Kejagung untuk diperiksa ketiga kalinya dalam kasus tersebut.\n",
      "\n",
      "ADVERTISEMENT SCROLL TO CONTINUE WITH CONTENT\n",
      "\n",
      "Pantauan CNNIndonesia.com, Nadiem datang bersama kuasa hukumnya Hotman Paris Hutapea. Eks bos Gojek itu membawa tas jinjing hitam ke dalam gedung Pidsus Kejagung dengan kemeja hijau.\n",
      "\n",
      "Sebelum hari ini Nadiem telah dua kali diperiksa sebagai saksi oleh Kejagung yakni pada Senin (23/6) dan Selasa (15/7).\n",
      "\n",
      "Dalam pemeriksaan itu, Kejagung mengusut keuntungan yang didapat Nadiem dalam dugaan korupsi pengadaan laptop. Selain itu, Nadiem juga didalami soal proses pengadaan laptop chromebook.\n",
      "\n",
      "Kejagung tengah mengusut kasus dugaan korupsi Program Digitalisasi Pendidikan di Kemendikbud periode 2019-2022. Selama periode itu, Kemendikbud mengadakan 1,2 juta unit laptop untuk sekolah-sekolah di Indonesia khususnya di daerah 3T dengan total anggaran mencapai Rp9,3 triliun.\n",
      "\n",
      "Pengadaan laptop ini dipilih menggunakan sistem operasi Chrome atau Chromebook meskipun memiliki banyak kelemahan dan tidak efektif untuk sarana pembelajaran pada daerah 3T karena belum memiliki akses internet.\n",
      "\n",
      "Dalam kasus ini, Kejagung menetapkan empat orang tersangka, tiga di antaranya adalah anak buah Nadiem saat di Kemendikbudristek.\n",
      "\n",
      "Adapun para empat tersangka itu adalah Direktur SMP Kemendikbudristek 2020-2021, Mulyatsyah; Direktur SD Kemendikbudristek 2020-2021, Sri Wahyuningsih; Mantan stafsus Mendikbudristek Nadiem Makarim, Jurist Tan; dan Mantan Konsultan Teknologi pada Kemendikbudristek, Ibrahim Arief.\n",
      "\n",
      "Atas perbuatan para tersangka, negara diduga mengalami kerugian hingga Rp1,98 triliun yang terdiri dari kerugian akibat Item Software (CDM) sebesar Rp480 miliar dan mark up harga laptop sebesar Rp1,5 triliun.\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.cnnindonesia.com/nasional/20250904130746-12-1270094/kejagung-tetapkan-nadiem-makarim-tersangka-kasus-pengadaan-laptop\"\n",
    "\n",
    "title, content = scrape_article(url)\n",
    "print(\"Title:\", title)\n",
    "print(\"Content:\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0ffb1f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "WHITESPACE_HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f9948145",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arvio\\anaconda3\\envs\\summarizer\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "c:\\Users\\Arvio\\anaconda3\\envs\\summarizer\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Arvio\\.cache\\huggingface\\hub\\models--csebuetnlp--mT5_multilingual_XLSum. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "model_name = \"csebuetnlp/mT5_multilingual_XLSum\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8f9473c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(\n",
    "    [WHITESPACE_HANDLER(content)],\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")[\"input_ids\"]\n",
    "\n",
    "output_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_length=84,\n",
    "    no_repeat_ngram_size=2,\n",
    "    num_beams=4\n",
    ")[0]\n",
    "\n",
    "summary = tokenizer.decode(\n",
    "    output_ids,\n",
    "    skip_special_tokens=True,\n",
    "    clean_up_tokenization_spaces=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e999a092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eks Mendikbudristek Nadiem Makarim ditetapkan sebagai tersangka oleh Kejaksaan Agung (Kejagung) dalam kasus dugaan korupsi Program Digitalisasi Pendidikan di Kemendikbud periode 2019-2023.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summarize",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
